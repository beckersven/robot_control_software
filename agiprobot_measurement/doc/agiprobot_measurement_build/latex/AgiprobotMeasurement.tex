%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional
  \DeclareUnicodeCharacter{"00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{"2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{"2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{"2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{"251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{"2572}{\textbackslash}
 \else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{2572}{\textbackslash}
 \fi
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage[dontkeepoldnames]{sphinx}

\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Explanation}}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}



\title{Agiprobot Measurement Documentation}
\date{Apr 27, 2021}
\release{1.0}
\author{Sven Becker}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}



\chapter{Overview}
\label{\detokenize{overview:overview}}\label{\detokenize{overview::doc}}\label{\detokenize{overview:agiprobot-measurement-s-documentation}}
This package provides a pipeline to plan, execute and handle a measurement-trajectory for a given CAD-object.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{overview}.png}
\end{figure}

The important module is {\hyperref[\detokenize{module_trajectory_manager:trajectory-manager}]{\sphinxcrossref{\DUrole{std,std-ref}{Trajectory Manager}}}}. It performs the motion planning pipeline with assistance by using the other modules {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}} and {\hyperref[\detokenize{module_sensor_model:sensor-model}]{\sphinxcrossref{\DUrole{std,std-ref}{Sensor Model}}}}.

During planning, {\hyperref[\detokenize{module_trajectory_manager:trajectory-manager}]{\sphinxcrossref{\DUrole{std,std-ref}{Trajectory Manager}}}} samples the surface of the target-mesh into discrete surface points and generates straight measurement-trajectories based on those points.
Starting at each surface point, the program places the \sphinxstyleemphasis{anchor} of a possible trajectory above this sample point and then processes the corresponding straight trajectory metrologically and mechanically.
To do so, the {\hyperref[\detokenize{module_sensor_model:sensor-model}]{\sphinxcrossref{\DUrole{std,std-ref}{Sensor Model}}}} is used to determine which other sample-points would be visible during this trajectory and how their uncertainties are. \sphinxhref{https://moveit.ros.org/}{MoveIt} is used to
review, if and how the trajectory-candidate is actually executable in the modeled scene (collision-awareness, reachablility, …). Both information - the sensor-evaluation and the kinematics - are then stored
into a {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}}-object. An algorithm is used to determine from the set of all viewpoints one subset, that covers all sampled surface points with an adjustable objective (like “minimize amount of viewpoints”), i.e. solves
the Set Covering Problem.
Afterwards, the chosen {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}}-objects are connected in a time-optimal way and the combined trajectory by connecting all viewpoint-trajectories and their in-between-segments can be executed or stored for later execution.


\chapter{Path Planning Detailed}
\label{\detokenize{view_planning_detailed:path-planning-detailed}}\label{\detokenize{view_planning_detailed::doc}}\label{\detokenize{view_planning_detailed:view-planning-detailed}}

\section{0. Load the Task}
\label{\detokenize{view_planning_detailed:load-the-task}}
Read in the given CAD-file of the target-object as well as its pose. The mesh is made available to the local trimesh-handler and loaded into the motion-planning-framework
\sphinxhref{https://moveit.ros.org}{MoveIt} so that it will be considered for collision-checks.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{moveit_collision_added}.png}
\end{figure}


\section{1. Preprocessing and Sampling}
\label{\detokenize{view_planning_detailed:preprocessing-and-sampling}}
Removes all downward facing surface faces since they are not considered measurable. This is based on the common assumption that the fixture holds the target object from below.
Use \sphinxhref{https://trimsh.org/}{trimesh} to sample the mesh’s surface into discrete surface-points depending on a specified sampling-density. The samples, corresponding face-normals and the target-mesh are
set as context in a {\hyperref[\detokenize{module_sensor_model:sensor-model}]{\sphinxcrossref{\DUrole{std,std-ref}{Sensor Model}}}}-instance.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{sampling_trimesh}.png}
\end{figure}


\section{2. ViewPoint-Generation and -Evaluation}
\label{\detokenize{view_planning_detailed:viewpoint-generation-and-evaluation}}
For each-sample, generate {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}}-objects by moving into the points face-normal and then applying rotations to get a variety of candidates per sampled surface point.
The resulting point is the anchor of the viewpoint. Each viewpoint is assigned a straight trajectory-line.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{trajectory_generation}.png}
\end{figure}

After that, 2 main evaluations are executed:


\subsection{Metrological Evaluation}
\label{\detokenize{view_planning_detailed:metrological-evaluation}}\begin{itemize}
\item {} 
Use the {\hyperref[\detokenize{module_sensor_model:sensor-model}]{\sphinxcrossref{\DUrole{std,std-ref}{Sensor Model}}}}-instance to analyze, which other sample-points are visible from this trajectory, and at what uncertainty

\item {} 
Result = Visibilities and uncertainties (will be stored in the {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}}-object)

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{measurement_example}.png}
\caption{Higher sampling density than previously for vividness. Red points are immeasurable; Green points are measurable at low uncertainty, blue ones at high uncertainty.}\label{\detokenize{view_planning_detailed:id3}}\end{figure}


\subsection{Mechanical Evaluation}
\label{\detokenize{view_planning_detailed:mechanical-evaluation}}\begin{itemize}
\item {} 
Utilize \sphinxhref{https://moveit.ros.org}{MoveIt} to examine, if this trajectory is actually executable in the scene (collision, reacability, …).

\item {} 
\sphinxstylestrong{Critical}: If the mechanical evaluation fails, the viewpoint will not be considered any further

\item {} 
Can also consider trajectory-parts: If e.g. 80\% of the trajectory are be executable, this {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}}-object might not be rejected

\item {} 
Result = List of actual joint-values (will be stored in the {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}}-object)

\end{itemize}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{collision_check}.png}
\end{figure}

The sequence of these evaluations is implemented in a way to minimize compute-time.


\section{3. ViewPoint-Selection (Set Covering Problem)}
\label{\detokenize{view_planning_detailed:viewpoint-selection-set-covering-problem}}
When a set of valid {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}} s has been found, not all {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}} -elements must be executed for a valid result: A subset must be found that
covers the same surface-points as all the found {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}} s (= \sphinxstyleemphasis{Set Covering Problem}). This subset is in general much smaller than the original set and can be built using different algorithms:

As the first option, ‘Greedy’ implementation (both used in the papers) selects in each iteration that new {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}} from the original set, that can contribute the most
not-yet-visible surface-sample-points to the subset. If 2 or more {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}} -objects can contribute the same amount, the one with the lowest uncertainty will be selected.

Another option is Integer Programming (IP):

Minimize \(\sum_{\forall i} c_j v_j\) subject to \(\sum_{\forall j} m_{i,j} v_j \ge 1~~~~\forall i\)

where \(v_j \in \{0,1\}\) indicates if viewpoint j is element of the subset and \(m_{i,j} \in \{0, 1\}\), if the sampled surface point i is measurable by the trajectory of viewpoint j.
\(c_{j}\) is a cost-term. If it is constant, the IP-problems is identically to the Greedy approach. However, by assigning \(c_{i}\) the time of the measurement-trajectory
of viewpoint i or its uncertainty, a bigger variety of solutions becomes possible than in the first option.


\section{4. Connecting the ViewPoints}
\label{\detokenize{view_planning_detailed:connecting-the-viewpoints}}
Lastly, the determined set of {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}}-objects must be ordered for optimal execution. To do so, the current robot-pose is enqueued in an ‘execution-list’.
Paths from the endpoint of the last element of execution-list are calculated to every non-enqueued viewpoint’s trajectory-start- and -endpoint. The {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}} with the shortest path-time becomes enqueued.
Also, the inter-viewpoint path will be stored in that {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}} so that it will perform the exact same path during execution (if the path would get planned again dynamically,
it might be completely different due to the stochastic nature of path-planning). This step relies again on \sphinxhref{https://moveit.ros.org}{MoveIt}.


\chapter{Trajectory Manager}
\label{\detokenize{module_trajectory_manager:trajectory-manager}}\label{\detokenize{module_trajectory_manager::doc}}\label{\detokenize{module_trajectory_manager:id1}}

\section{Introduction and Basic Ideas}
\label{\detokenize{module_trajectory_manager:introduction-and-basic-ideas}}
This module provides an configurable system to plan, execute, store and load measurement-trajectories for scanning objects with a laser-line-scanner mounted on a robotic arm.

The planning is heavily inspired by \sphinxhref{https://iopscience.iop.org/article/10.1088/2051-672X/4/2/024009}{“View and sensor planning for multi-sensor surface inspection” (Gronle et al., 2016)}
and \sphinxhref{https://link.springer.com/article/10.1007/s00138-007-0110-2}{“Model-based view planning” (Scott, 2009)}, however this module was adapted to fit this use-case and general improvements were incorporated.

For a given task, the user can specifiy the mesh-to-measure, properties of the trajectory-segments (like lenght) and other parameters.
Then, the planning-pipeline discussed in section {\hyperref[\detokenize{view_planning_detailed:view-planning-detailed}]{\sphinxcrossref{\DUrole{std,std-ref}{Path Planning Detailed}}}}, will be performed. Afterwards, the generated total trajectory can be executed via
\sphinxhref{https://moveit.ros.org}{MoveIt} on the real robot or in a simulation (see CoppeliaSim-Interface’s documentation in that case). The trajectory can also be
written to disk for later or repetitive execution. As ‘good’ trajectories currently require long calculations (\textgreater{}30min),
this module enables users to load and execute previously computed trajectories.


\section{API-Specification}
\label{\detokenize{module_trajectory_manager:api-specification}}\label{\detokenize{module_trajectory_manager:module-agiprobot_measurement.trajectory_manager}}\index{agiprobot\_measurement.trajectory\_manager (module)}\index{TrajectoryManager (class in agiprobot\_measurement.trajectory\_manager)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager}}\pysigline{\sphinxbfcode{class }\sphinxcode{agiprobot\_measurement.trajectory\_manager.}\sphinxbfcode{TrajectoryManager}}
Completely integrated system for high-coverage and uncertainty-minimal scanning of given objects with an optical scanner. An instance can perform
the entire planning pipeline - from the CAD-file and pose to a list of consecutively executable trajectories.
\index{connect\_viewpoints() (agiprobot\_measurement.trajectory\_manager.TrajectoryManager method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager.connect_viewpoints}}\pysiglinewithargsret{\sphinxbfcode{connect\_viewpoints}}{\emph{unordered\_viewpoints}, \emph{min\_planning\_time=0.2}}{}
Connect a set of unordered viewpoints with the current state and in between greedily so that they can be executed as fast as possible.
Until all viewpoints are enqueued, do: From the end-point of the last enqueued trajetory, motion plans are calculated to the start-/end-poses
of all unenqueued viewpoint’s measurement-trajectories and the shortest (in time domain) will be selected.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{unordered\_viewpoints} (\sphinxstyleliteralemphasis{set}\sphinxstyleliteralemphasis{{[}}{\hyperref[\detokenize{module_view:module-agiprobot_measurement.viewpoint}]{\sphinxcrossref{\sphinxstyleliteralemphasis{viewpoint}}}}\sphinxstyleliteralemphasis{{]}}) \textendash{} Set of viewpoints to be connected where each has a stored measurement-trajectory

\item {} 
\sphinxstyleliteralstrong{min\_planning\_time} (\sphinxstyleliteralemphasis{float}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Planning time that is used for connection-path-planning (will be increased automatically if no plan was found at first), defaults to 0.2

\end{itemize}

\item[{Returns}] \leavevmode
List of ordered and execution-ready viewpoints

\item[{Return type}] \leavevmode
list{[}{\hyperref[\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint}]{\sphinxcrossref{ViewPoint}}}{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{convert\_viewpointlist\_to\_execution\_plan() (agiprobot\_measurement.trajectory\_manager.TrajectoryManager method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager.convert_viewpointlist_to_execution_plan}}\pysiglinewithargsret{\sphinxbfcode{convert\_viewpointlist\_to\_execution\_plan}}{\emph{viewpointlist}}{}
Convert a list of ViewPoint-objects into a list of moveit\_msgs/RobotTrajectory-entries so that the viewpoints can be executed consecutively.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{viewpointlist} \textendash{} List of ViewPoint-objects with set trajectories for steering-to-viewpoint and measurement

\item[{Returns}] \leavevmode
List of moveit\_msgs/RobotTrajectory with 2 entries per provided ViewPoint-object (first = steering-to-viewpoint-trajectory, second = measurement-trajectory)

\item[{Return type}] \leavevmode
list

\end{description}\end{quote}

\end{fulllineitems}

\index{execute() (agiprobot\_measurement.trajectory\_manager.TrajectoryManager method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager.execute}}\pysiglinewithargsret{\sphinxbfcode{execute}}{\emph{execution\_list}, \emph{surface\_points=None}}{}
Execute a list of RobotTrajectories or ViewPoints via MoveIt. When problems occur during execution,
the robot will be stopped and an exception will be raised. When executing from a list of viewpoints, the currently measured surface\_points
are published in “/currently\_measured\_points” during execution.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{execution\_list} (\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{moveit\_msgs/RobotTrajectory}\sphinxstyleliteralemphasis{{]} or }\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}{\hyperref[\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint}]{\sphinxcrossref{\sphinxstyleliteralemphasis{ViewPoint}}}}\sphinxstyleliteralemphasis{{]}}) \textendash{} List of RobotTrajectories or viewpoints that can be executed consecutively (the next segment’s start point is the last segment’s end point)

\item {} 
\sphinxstyleliteralstrong{surface\_points} (\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{numpy.array}\sphinxstyleliteralemphasis{{]}}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} List of the actual sampled surface points, defaults to None

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{generate\_samples\_and\_viewpoints() (agiprobot\_measurement.trajectory\_manager.TrajectoryManager method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager.generate_samples_and_viewpoints}}\pysiglinewithargsret{\sphinxbfcode{generate\_samples\_and\_viewpoints}}{\emph{sampling\_density}, \emph{uncertainty\_threshold}, \emph{orientations\_around\_boresight}, \emph{viewpoint\_tilt\_mode='full'}, \emph{plan\_path\_to\_check\_reachability=False}, \emph{minimum\_trajectory\_length=25}, \emph{trajectory\_sample\_step=2}}{}
Samples the mesh’s surface into discrete points, generates viewpoints for each sample and processes these viewpoints metrologically and mechanically.
Only viewpoints that do meet the contraints specified in the method’s parameters and in MoveIt (collision, reachability, …) will be returned. This method allows to generate
multiple ViewPoint-objects for a single surface-point by varying the anchor-pose (the boresight is always focused on the corresponding surface\_point).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{sampling\_density} (\sphinxstyleliteralemphasis{float}) \textendash{} Density of sampling to generate the points for measurement-calculations and viewpoint-generation in points per mm\textasciicircum{}2

\item {} 
\sphinxstyleliteralstrong{orientations\_around\_boresight} (\sphinxstyleliteralemphasis{int}) \textendash{} Number of orientations around the sensor’s boresight to be considered per sampled\_surface\_point

\item {} 
\sphinxstyleliteralstrong{viewpoint\_tilt\_mode} (\sphinxstyleliteralemphasis{str}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} 
For each orientation, deviate the psi- and theta-values of the viewpoint-anchor-pose slightly from the optimum according to (one deviation-step per angle and orientation available right now):
\begin{itemize}
\item {} 
”none”: Do not perform any tilting.

\item {} 
”limited”: When the optimal angle-configuration did not work, try deviations and stop after finding the first valid solution.

\item {} 
”full”: Calculation for every possible angle-calculation. Every boresight orientation has 9 sub-viewpoints.

\end{itemize}

, defaults to “full”


\item {} 
\sphinxstyleliteralstrong{plan\_path\_to\_check\_reachability} (\sphinxstyleliteralemphasis{bool}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Do not use one inverse-kinematics-request to check viewpoint-reachability but try to create complete plan from the current-state to the viewpoint’s anchor-pose, defaults to False

\item {} 
\sphinxstyleliteralstrong{minimum\_trajectory\_length} (\sphinxstyleliteralemphasis{float}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Minimum length a generated trajectory has to have so that it is accepted in mm, defaults to 50

\item {} 
\sphinxstyleliteralstrong{trajectory\_sample\_step} (\sphinxstyleliteralemphasis{float}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Euclidian distance between 2 trajectory-points in cartesian sapce in mm, defaults to 2

\end{itemize}

\item[{Returns}] \leavevmode
2 lists with the first containing all sampled\_surface\_points and the second containing all viewpoints that were processed successfully

\item[{Return type}] \leavevmode
list{[}numpy.array{]}, list{[}{\hyperref[\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint}]{\sphinxcrossref{ViewPoint}}}{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_execution\_plan() (agiprobot\_measurement.trajectory\_manager.TrajectoryManager method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager.load_execution_plan}}\pysiglinewithargsret{\sphinxbfcode{load\_execution\_plan}}{\emph{file\_path}, \emph{adapt\_to\_current\_start\_pose=True}}{}
Extracts a list of moveit\_msgs/RobotTrajectory specified in the yaml-file at the provided path.

The trajectories can be executed consecutively, however if the execution should start from the current state (which is most
likely the case), the parameter ‘adapt\_to\_current\_start\_pose’ should be set true to add movement from the current point (which
in general deviates from the ‘current point’ during planning) to the trajectory start. The yaml-file must correspond to a list with the first
entry being a dictionary for metadata and the following entries being dictionaries of ‘expanded’ RobotTrajectories with following structure:
Trajecories connecting measurements (C) and measurement trajectories (M) themselves in an alternating fashion (C-M-C-M-C-…).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{file\_path} (\sphinxstyleliteralemphasis{str}) \textendash{} Where the yaml-file is located

\item {} 
\sphinxstyleliteralstrong{adapt\_to\_current\_start\_pose} (\sphinxstyleliteralemphasis{bool}) \textendash{} If true (default), the plan will be adapted so that it can start from the current state

\end{itemize}

\item[{Returns}] \leavevmode
List of moveit\_msgs/RobotTrajectory-ies that can be consecutively executed

\item[{Return type}] \leavevmode
list

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_target\_mesh() (agiprobot\_measurement.trajectory\_manager.TrajectoryManager method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager.load_target_mesh}}\pysiglinewithargsret{\sphinxbfcode{load\_target\_mesh}}{\emph{file\_name, transform=array({[}{[}1., 0., 0., 0.{]},        {[}0., 1., 0., 0.{]},        {[}0., 0., 1., 0.{]},        {[}0., 0., 0., 1.{]}{]}), add\_wbk\_mirrors=True, remove\_downside=True, remove\_threshold\_angle\_deg=20}}{}
Loads the mesh-to-measure from file into the instance’s target\_mesh-member (to generate and evaluate viewpoint-trajectories) and into
MoveIt (for collision-prevention). To move the mesh into a feasible measurement-pose, a transform may be applied to set the mesh’s
reference frame specified in CAD with respect to the ‘world’ frame
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{file\_name} (\sphinxstyleliteralemphasis{str}) \textendash{} Where the target\_mesh’s CAD file is located (should be given starting at root-level: ‘/X/Y/…’)

\item {} 
\sphinxstyleliteralstrong{transform} (\sphinxstyleliteralemphasis{numpy.array}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Homogeneous 4x4-matrix to move the mesh into the desired pose with translation in mm, defaults to identity-matrix

\item {} 
\sphinxstyleliteralstrong{add\_wbk\_mirrors} (\sphinxstyleliteralemphasis{bool}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Adds hard-coded collision objects to MoveIt as the robot station at the institute is placed besides 2 fragile mirrors, defaults to True

\end{itemize}

\item[{Returns}] \leavevmode
Whether all operations (esp. loading from file into trimesh and MoveIt) were successful

\item[{Return type}] \leavevmode
bool

\end{description}\end{quote}

\end{fulllineitems}

\index{postprocess\_trajectory() (agiprobot\_measurement.trajectory\_manager.TrajectoryManager method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager.postprocess_trajectory}}\pysiglinewithargsret{\sphinxbfcode{postprocess\_trajectory}}{\emph{trajectory}}{}
Check if trajectory meets the limits specified in ‘joint\_limits.yaml’ and if the time between two points is increasing.
MoveIt does not apply the values from ‘joint\_limits.yaml’ when computing a cartesian path, which is dangerous for trajectory-execution.
For prevention, trajectories with too heavy violations will be rejected. However, specifying the joint-limits from the yaml in the xacro-urdf as
well seems to have eliminated this problem (but this code is still active for safety purposes).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{trajectory} (\sphinxstyleliteralemphasis{moveit\_msgs/RobotTrajectory}) \textendash{} RobotTrajectory to check and improve

\item[{Returns}] \leavevmode
Boolean value indicating if the trajectory could be post-processed reasonably or if it has to be rejected

\item[{Return type}] \leavevmode
bool

\end{description}\end{quote}

\end{fulllineitems}

\index{process\_viewpoint() (agiprobot\_measurement.trajectory\_manager.TrajectoryManager method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager.process_viewpoint}}\pysiglinewithargsret{\sphinxbfcode{process\_viewpoint}}{\emph{viewpoint}, \emph{ik\_service}, \emph{uncertainty\_threshold}, \emph{minimum\_required\_overmeasure=5}, \emph{trajectory\_sample\_step=2}, \emph{joint\_jump\_threshold=1.5}, \emph{minimum\_trajectory\_length=50}}{}
Processes a single viewpoint entirely. Starting on a simple reachability-analysis of the anchor-pose, a metrological evaluation is performed using the sensor\_model to
reviewpoint the measurement-gain this viewpoint can contribute in theory. Then, the actual meausrement-trajectories are calculated and examined regarding the
provided contraints. In the end, the processing-result (trajectory and metrological values) are stored in the viewpoint object
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{viewpoint} ({\hyperref[\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint}]{\sphinxcrossref{\sphinxstyleliteralemphasis{ViewPoint}}}}) \textendash{} ViewPoint to be processed (if processing was successful, members of this viewpoint-object will be changed)

\item {} 
\sphinxstyleliteralstrong{ik\_service} (\sphinxstyleliteralemphasis{rospy.ServiceProxy}) \textendash{} ROS-Serviceproxy that can resolve inverse-kinematics via moveit\_msgs/GetPositionIK

\item {} 
\sphinxstyleliteralstrong{minimum\_required\_overmeasure} (\sphinxstyleliteralemphasis{float}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} How much to add to the trajectory in trajectory-direction in mm after the last measurable sample\_point is measured (as samples usually do not occur exactly at edges), defaults to 5

\item {} 
\sphinxstyleliteralstrong{trajectory\_sample\_step} (\sphinxstyleliteralemphasis{float}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Euclidian distance between 2 trajectory-points in cartesian sapce in mm, defaults to 2

\item {} 
\sphinxstyleliteralstrong{joint\_jump\_threshold} (\sphinxstyleliteralemphasis{float}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Maximum change in joint values allowed between 2 trajectory-points in rad (since all joints are revolute), defaults to 1.5

\item {} 
\sphinxstyleliteralstrong{minimum\_trajectory\_length} (\sphinxstyleliteralemphasis{float}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Minimum length a generated trajectory has to have so that it is accepted in mm, defaults to 50

\end{itemize}

\item[{Returns}] \leavevmode
Boolean value that is true, if the viewpoint could be processed and all contraints were met, and false otherwise

\item[{Return type}] \leavevmode
bool

\end{description}\end{quote}

\end{fulllineitems}

\index{solve\_scp() (agiprobot\_measurement.trajectory\_manager.TrajectoryManager method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager.solve_scp}}\pysiglinewithargsret{\sphinxbfcode{solve\_scp}}{\emph{provided\_viewpoints}, \emph{solver\_type='greedy'}}{}
Solve Set Covering Problem to cover all measurable surface\_points with a fraction of the set of provided viewpoints.
Possible solver\_types are:
\begin{itemize}
\item {} 
“greedy”: Fills return set at each step with the trajectory that delivers the most
additional coverage compared to the points already in the set. If this additional coverage is
identical in size for several new optimal viewpointpoint-candidates, the one with the lowest maximum
uncertainty will be added similarly to the improvement introduced in chapter 4.4 of 
“ViewPoint and sensor planning for multi-sensor surface inspection” (Gronle et al., 2016)  (default)

\item {} 
“IP\_basic”: Solves the SCP-Problem with integer programming (IP) using the formulation in
“Model-based viewpoint planning” (Scott, 2009), i.e. the objective function is the number of all
selected viewpointpoints whereas the constraint is that every surface point must be covered at least by one viewpointpoint

\item {} 
“IP\_uncertainty”: Solves the SCP using IP with respect to the uncertainty. The formulas are similar to “IP\_basic”
but in the objective, costs corresponding to the worst uncertainty are assigned to every viewpointpoint-trajectory.

\item {} 
“IP\_time”: Solves the SCP using IP with respect to the time of trajectory-execution. The formulas are similar to “IP\_basic”
but in the objective, costs corresponding to the duration of the trajectory are assigned to every viewpointpoint.

\end{itemize}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{provided\_viewpoints} (\sphinxstyleliteralemphasis{set}\sphinxstyleliteralemphasis{{[}}{\hyperref[\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint}]{\sphinxcrossref{\sphinxstyleliteralemphasis{ViewPoint}}}}\sphinxstyleliteralemphasis{{]} or }\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}{\hyperref[\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint}]{\sphinxcrossref{\sphinxstyleliteralemphasis{ViewPoint}}}}\sphinxstyleliteralemphasis{{]}}) \textendash{} All processed viewpoints where each has a valid measurement-trajectory and information about the measurable surface\_points

\item {} 
\sphinxstyleliteralstrong{solver\_type} (\sphinxstyleliteralemphasis{str}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} See function description, defaults to “greedy”

\end{itemize}

\item[{Returns}] \leavevmode
Set of viewpoints that can measure the union of measurable surface points of all provided viewpoints

\item[{Return type}] \leavevmode
set{[}{\hyperref[\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint}]{\sphinxcrossref{ViewPoint}}}{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{store\_execution\_plan() (agiprobot\_measurement.trajectory\_manager.TrajectoryManager method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_trajectory_manager:agiprobot_measurement.trajectory_manager.TrajectoryManager.store_execution_plan}}\pysiglinewithargsret{\sphinxbfcode{store\_execution\_plan}}{\emph{file\_path}, \emph{execution\_plan}, \emph{metadata=\{\}}}{}
Stores the provided execution\_plan segments (= moveit\_msgs/RobotTrajectory) in a yaml-file at the provided file\_path formatted so that it can be read in by the class’s ‘load\_execution\_plan’-method.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{file\_path} (\sphinxstyleliteralemphasis{str}) \textendash{} Path specifying where to safe the generated file at

\item {} 
\sphinxstyleliteralstrong{execution\_plan} (\sphinxstyleliteralemphasis{list of moveit\_msgs/RobotTrajectory}) \textendash{} List of path-segments that can be executed consecutively (i.e. joint-values at the last point of any entry = joint-values at the beginning of the next entry).

\item {} 
\sphinxstyleliteralstrong{metadata} (\sphinxstyleliteralemphasis{dict}) \textendash{} Dictionary of information about this plan in key-value-fashion (e.g. \{‘sampling\_density’: 0.01, ‘timestamp’: ‘12:00, 01.01.2021’, ‘planning\_duration\_in\_s’:42\}”)\#

\end{itemize}

\item[{Returns}] \leavevmode
True (always)

\item[{Return type}] \leavevmode
bool

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Sensor Model}
\label{\detokenize{module_sensor_model::doc}}\label{\detokenize{module_sensor_model:sensor-model}}\label{\detokenize{module_sensor_model:id1}}

\section{Introduction and Basic Ideas}
\label{\detokenize{module_sensor_model:introduction-and-basic-ideas}}
The Sensor Model is a utility-module to perform metrological evaluations on a given input.

The mathematical foundation of the model is derived in the corresponding
Bachelor’s Thesis, however the theoretical understanding is not needed to work with this module. One task is to make qualified predictions about the uncertainty
of a given point within the scanners visibility, when certain spatial information (see below) is given. Within the {\hyperref[\detokenize{module_trajectory_manager:trajectory-manager}]{\sphinxcrossref{\DUrole{std,std-ref}{Trajectory Manager}}}}’s pipeline, this module
can also be used to determine which points can be measured and how ‘uncertain’ this measure for a {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}}-object’s trajectory given the occluding target-mesh,
possible sampled surface points, … (‘context’).


\subsection{Commonly Used Geometric Terms}
\label{\detokenize{module_sensor_model:commonly-used-geometric-terms}}
See the image below for additional context.
\begin{itemize}
\item {} 
laser\_emitter\_frame: See {\hyperref[\detokenize{module_view:viewpoint}]{\sphinxcrossref{\DUrole{std,std-ref}{ViewPoint}}}}

\item {} 
psi/\(\psi\): Angle between the laser\_emitter\_frame’s z-y-plane and the surface-normal of the sample

\item {} 
theta/\(\vartheta\):  Angle between the in normal-vector and the laser-emitter-ray-direction towards the sample, projected on the y-z-plane

\item {} 
\(z\): Distance of the sample-point projected onto the z-axis of the laser\_emitter\_frame = Distance from the x-y-plane of the laser\_emitter\_frame

\item {} 
\(\alpha, K_{u}, u_{0}\): Symbols of the uncertainty-formular (not important to use the sensor-model, detailed description in accompanying Bachelor’s Thesis)

\end{itemize}


\subsection{Visualization of Concepts}
\label{\detokenize{module_sensor_model:visualization-of-concepts}}
\sphinxstylestrong{Mind the orientation of the green laser\_emitter\_frame!}


\subsubsection{Perpendicular To Laser-Fan}
\label{\detokenize{module_sensor_model:perpendicular-to-laser-fan}}
\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{sensor_parameters_1}.png}
\end{figure}


\subsubsection{Parallel To Laser-Fan}
\label{\detokenize{module_sensor_model:parallel-to-laser-fan}}
\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{sensor_parameters_2}.png}
\end{figure}


\section{API-Specification}
\label{\detokenize{module_sensor_model:api-specification}}\label{\detokenize{module_sensor_model:module-agiprobot_measurement.sensor_model}}\index{agiprobot\_measurement.sensor\_model (module)}\index{SensorModel (class in agiprobot\_measurement.sensor\_model)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_sensor_model:agiprobot_measurement.sensor_model.SensorModel}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{agiprobot\_measurement.sensor\_model.}\sphinxbfcode{SensorModel}}{\emph{parameter\_map}}{}
Computional representation of an laser triangulation sensor under influence of uncertainty.
\index{evaluate\_score() (agiprobot\_measurement.sensor\_model.SensorModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_sensor_model:agiprobot_measurement.sensor_model.SensorModel.evaluate_score}}\pysiglinewithargsret{\sphinxbfcode{evaluate\_score}}{\emph{z}, \emph{psi}}{}
Calculates a score of uncertainty \(\in [0,1]\) for the given z and psi (higher score means lower uncertainty). The score
is linear affine in the uncertainty based on z and psi - It is 1 if the provided values match the best possible case (lowest
possible uncertainty of the sensor model) and 0 when both values are right at the rejection limit (i.e. are equal to {\color{red}\bfseries{}max\_deviation\_}…):
\(\frac{u_{max} - u(z, \psi)}{u_{max} - u_{min}}\)
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{z} (\sphinxstyleliteralemphasis{float}) \textendash{} z-coordinate of the point to evaluate in the laser\_emitter\_frame in mm

\item {} 
\sphinxstyleliteralstrong{psi} (\sphinxstyleliteralemphasis{float}) \textendash{} Angle of the laser\_emitter\_frame’s z-y-plane with the surface-triangle of the point to evaluate in rad

\end{itemize}

\item[{Returns}] \leavevmode
Score \(\in [0,1]\) based on the parameters and the max\_deviations of them

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{evaluate\_uncertainty() (agiprobot\_measurement.sensor\_model.SensorModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_sensor_model:agiprobot_measurement.sensor_model.SensorModel.evaluate_uncertainty}}\pysiglinewithargsret{\sphinxbfcode{evaluate\_uncertainty}}{\emph{z}, \emph{psi}}{}
Computes the uncertainty of a surface point with given z and psi using the specified geometric sensor parameters.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{z} (\sphinxstyleliteralemphasis{float}) \textendash{} z-coordinate of the point to evaluate in the laser\_emitter\_frame in mm

\item {} 
\sphinxstyleliteralstrong{psi} (\sphinxstyleliteralemphasis{float}) \textendash{} Angle of the laser\_emitter\_frame’s z-y-plane with the surface-triangle of the point to evaluate in rad

\end{itemize}

\item[{Returns}] \leavevmode
Uncertainty based on the z, psi, and the geometric sensor parameters, or ‘NaN’ if z and psi are invalid

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_max\_uncertainty() (agiprobot\_measurement.sensor\_model.SensorModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_sensor_model:agiprobot_measurement.sensor_model.SensorModel.get_max_uncertainty}}\pysiglinewithargsret{\sphinxbfcode{get\_max\_uncertainty}}{}{}
Computes maximum possible uncertainty of a measured point that is not rejected using geometric sensor parameters. 
The uncertainty-formula is evaluated at z- and psi-values that are at rejection-limits for a surface point, so that this value corresponds
to the worst uncertainty assignable to a measurable point.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
Maximum possible uncertainty of a measurable point (= is within the {\color{red}\bfseries{}max\_deviation\_}…-range) in mm

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_median\_deviation\_angle() (agiprobot\_measurement.sensor\_model.SensorModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_sensor_model:agiprobot_measurement.sensor_model.SensorModel.get_median_deviation_angle}}\pysiglinewithargsret{\sphinxbfcode{get\_median\_deviation\_angle}}{}{}
Get the smallest angle allowed for tilting (smallest of maximum deviations of theta and psi devided by 2).
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
Smallest angle allowed for tilting

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_min\_uncertainty() (agiprobot\_measurement.sensor\_model.SensorModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_sensor_model:agiprobot_measurement.sensor_model.SensorModel.get_min_uncertainty}}\pysiglinewithargsret{\sphinxbfcode{get\_min\_uncertainty}}{}{}
Computes the minimum possible uncertainty using the geometric sensor parameters. It returns the uncertainty value assignable to
a surface point which has been measured with optimal z- and psi-values, i.e. the best-case.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
Minimum possible uncertainty in mm

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_optimal\_standoff() (agiprobot\_measurement.sensor\_model.SensorModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_sensor_model:agiprobot_measurement.sensor_model.SensorModel.get_optimal_standoff}}\pysiglinewithargsret{\sphinxbfcode{get\_optimal\_standoff}}{}{}
Gets the optimal standoff, i.e. required the .
The returned optimal standoff is not equal to the standoff providing the lowest uncertainty, but in the center between the z-rejection-limits
to allow maximum flexibility in surface height deviation when moving the sensor.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
z-coordinate in the laser\_emitter\_frame of an surface point for measurement in mm

\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_scanning\_frustum() (agiprobot\_measurement.sensor\_model.SensorModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_sensor_model:agiprobot_measurement.sensor_model.SensorModel.get_scanning_frustum}}\pysiglinewithargsret{\sphinxbfcode{get\_scanning\_frustum}}{\emph{half\_length}}{}
Generates a trimesh-mesh object representing the ‘frustum of measurability’ in the laser\_emitter\_frame. Points within this frustum have 
the potential to be measurable, but {\color{red}\bfseries{}maximum\_deviation\_}… may still reject points within this frustum. The frustum is constructed based on
the laser-fan-angle and the allowed z-range and the idea that the trajectory is a straight line (it can be imagined as a cut-off ‘Toblerone’). 
So points lying wthin this frustum can be touched by the laser line AND can be mapped to the optical sensor.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{half\_length} (\sphinxstyleliteralemphasis{float}) \textendash{} Length of the frustum perpendicular to the fan-plane in each direction of the laser\_emitter\_frame in mm

\item[{Returns}] \leavevmode
Scan frustum represting the volume of potentially measurable points

\item[{Return type}] \leavevmode
trimesh.Trimesh

\end{description}\end{quote}

\end{fulllineitems}

\index{process\_viewpoint\_metrologically() (agiprobot\_measurement.sensor\_model.SensorModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_sensor_model:agiprobot_measurement.sensor_model.SensorModel.process_viewpoint_metrologically}}\pysiglinewithargsret{\sphinxbfcode{process\_viewpoint\_metrologically}}{\emph{viewpoint}, \emph{uncertainty\_threshold}, \emph{maximum\_deflection=500.0}}{}
Computes all measurable surface-points by a viewpoint-object as well as uncertainties and where they are measurable on the viewpoint-measurement-trajectory.
Requires context to be set via set\_processing\_context(…). Checks for every sampled surface point of the given context whether it is visible and calculates the
uncertainty for it eventually. Also, the deflection of the laser\_emitter\_frame along the trajectory-line from the viewpoint-anchor pose is evaluated.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{viewpoint} ({\hyperref[\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint}]{\sphinxcrossref{\sphinxstyleliteralemphasis{ViewPoint}}}}) \textendash{} ViewPoint with set viewpoint-anchor-pose

\item {} 
\sphinxstyleliteralstrong{uncertainty\_threshold} (\sphinxstyleliteralemphasis{float}) \textendash{} Maximum permissible uncertainty of a measured surface point, in mm

\item {} 
\sphinxstyleliteralstrong{maximum\_deflection} (\sphinxstyleliteralemphasis{float}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Maximum deflection of the trajectory to be considered for processing in mm, defaults to 5e2

\end{itemize}

\item[{Returns}] \leavevmode

3 unpacked arrays of the same length in order:
\begin{itemize}
\item {} 
Indices of the measurable surface points in samples\_surface\_points\_list

\item {} 
Corresponding uncertainty-scores

\item {} 
Metric distance in mm in trajectory-direction from the viewpoint-anchor where the corresponding surface point is measurable

\end{itemize}


\item[{Return type}] \leavevmode
array{[}int{]}, array{[}float{]}, array{[}float{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_processing\_context() (agiprobot\_measurement.sensor\_model.SensorModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_sensor_model:agiprobot_measurement.sensor_model.SensorModel.set_processing_context}}\pysiglinewithargsret{\sphinxbfcode{set\_processing\_context}}{\emph{mesh}, \emph{sampled\_surface\_points}, \emph{sampled\_face\_indices}}{}
Loads a context for metrological processing to the sensor model.
This includes loading the target mesh into a ray-tracer as well as gaining awareness over the
sampling results because they are directly used to assess a ViewPoint during process\_viewpoint\_metrologically().
This method must be called before any metrological processing can be performed. A previously set
context becomes overwritten completely by calling this method again.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{mesh} (\sphinxstyleliteralemphasis{trimesh.Trimesh}) \textendash{} Mesh-object to load into the RayMeshIntersector

\item {} 
\sphinxstyleliteralstrong{sampled\_surface\_points} (\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{numpy.array}\sphinxstyleliteralemphasis{{]}}) \textendash{} List of all sampled surface points that should be considered for the metrological processing

\item {} 
\sphinxstyleliteralstrong{sampled\_face\_ids} (\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{int}\sphinxstyleliteralemphasis{{]}}) \textendash{} List of face-indices, where each entry corresponds to the face of the sampled surface point at the same position

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{ViewPoint}
\label{\detokenize{module_view::doc}}\label{\detokenize{module_view:viewpoint}}\label{\detokenize{module_view:id1}}

\section{Introduction and Basic Ideas}
\label{\detokenize{module_view:introduction-and-basic-ideas}}
A ViewPoint is a container of one measurement-trajectory with extra-functionality.

It can store besides the actual measurement-trajectory another trajectory towards its
measurement trajectory as well as quantitative metrological predictions about the measurement. A View can construct itself in a bare geometrical sense: Given a surface point,
a anchor-position as well as an orientation of the laser\_emitter\_frame are created so that the z-axis of this frame points towards this surface\_point, when in anchor-position.


\subsection{Commonly Used Terms}
\label{\detokenize{module_view:commonly-used-terms}}\begin{itemize}
\item {} 
surface-point: The sampled surface point on the target-mesh this viewpoint is based on

\item {} 
anchor-position: The position this viewpoint’s trajectory goes through and where its laser\_emitter\_frame’s z-axis points towards the corresponding surface-point

\item {} \begin{description}
\item[{laser\_emitter\_frame: Frame positioned at the scanners’s laser-emitter (“where the laser leaves the scanner”) that is moved along the straight trajectory during execution}] \leavevmode\begin{itemize}
\item {} 
x-axis points in the trajectory-direction

\item {} 
z-axis points towards the corresponding surface-point when it becomes measured

\item {} 
y-axis results from the right-handedness of the coordinate-system

\item {} 
During trajectory-execution, the orientation of this frame is constant in the ‘world’-frame but the position changes

\end{itemize}

\end{description}

\item {} 
angle-around-boresight: Angle for rotation of this viewpoints straight-trajectory around the laser\_emitter\_frame’s z-axis in anchor-position

\end{itemize}


\subsection{Visualization of Concepts}
\label{\detokenize{module_view:visualization-of-concepts}}
\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{view_geometry}.png}
\end{figure}


\section{API-Specification}
\label{\detokenize{module_view:module-agiprobot_measurement.viewpoint}}\label{\detokenize{module_view:api-specification}}\index{agiprobot\_measurement.viewpoint (module)}\index{ViewPoint (class in agiprobot\_measurement.viewpoint)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{agiprobot\_measurement.viewpoint.}\sphinxbfcode{ViewPoint}}{\emph{surface\_point}, \emph{surface\_normal}, \emph{angle\_around\_boresight}, \emph{standoff\_distance}, \emph{tilt\_theta=0}, \emph{tilt\_psi=0}}{}
Class for keeping track about one viewpoint.
A viewpoint consists on the one hand of geometrical specifications (about location and length of the viewpointand execution informations), on the other
hand of metrological specifications (e.g. what can be measured by this viewpoint).
\index{get\_anchor\_position() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.get_anchor_position}}\pysiglinewithargsret{\sphinxbfcode{get\_anchor\_position}}{\emph{as\_matrix=False}}{}
Gets the laser\_emitter\_frame’s position that was generated during construction. This is the point where the z-axis of the laser\_emitter\_frame
hits the surface\_point of the target mesh that was used to design this viewpoint. Keep in mind that ‘anchor’ does not necessarely mean ‘anchor’ of the trajectory.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{as\_matrix} (\sphinxstyleliteralemphasis{bool}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Whether to give the translation as homogeneous 4x4-matrix or vector, defaults to False

\item[{Returns}] \leavevmode
Homogeneous 4x4-matrix or vector of the view’s anchor position

\item[{Return type}] \leavevmode
np.array (dimensions depend on parameter as\_matrix)

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_measurable\_surface\_point\_indices() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.get_measurable_surface_point_indices}}\pysiglinewithargsret{\sphinxbfcode{get\_measurable\_surface\_point\_indices}}{}{}
Gets the surface\_point-indices measurable by this view’s measurement-trajectory. The indices are abstract and are only useful 
when inserted into an externally maintained list of the actual surface points.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
Surface\_point-indices measurable by this view’s measurement-trajectory of an external list

\item[{Return type}] \leavevmode
list{[}int{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_measurable\_surface\_point\_uncertainties() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.get_measurable_surface_point_uncertainties}}\pysiglinewithargsret{\sphinxbfcode{get\_measurable\_surface\_point\_uncertainties}}{}{}
Gets the uncertainties of each measurable surface point. The values in the returned list must be matched with the
actual surface points in an external viewpoint list using this views measurable\_surface\_point\_indices: The uncertainty at index i
is meant for the surface\_point in the external list evaluated at index measurable\_surface\_point\_indices{[}i{]}.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
uncertainties of each measurable surface point

\item[{Return type}] \leavevmode
list{[}float{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_orientation\_matrix() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.get_orientation_matrix}}\pysiglinewithargsret{\sphinxbfcode{get\_orientation\_matrix}}{}{}
Gets the orientation of the laser\_emitter\_frame of this viewpoint. The orientation (not the position) remains the same for every point on the assigned measurement-trajectory
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
Orientation of the laser\_emitter\_frame

\item[{Return type}] \leavevmode
numpy.array

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_surface\_point() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.get_surface_point}}\pysiglinewithargsret{\sphinxbfcode{get\_surface\_point}}{\emph{as\_matrix=False}}{}
Gets the position of the surface point this viewpoint is based on. This is not the same as the view\_anchor-point.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{as\_matrix} (\sphinxstyleliteralemphasis{bool}\sphinxstyleliteralemphasis{, }\sphinxstyleliteralemphasis{optional}) \textendash{} Whether to give the translation as homogeneous 4x4-matrix or vector, defaults to False

\item[{Returns}] \leavevmode
Homogeneous 4x4-matrix or vector of the surface point

\item[{Return type}] \leavevmode
numpy.array (dimensions depend on parameter as\_matrix)

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_trajectory\_for\_measurement() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.get_trajectory_for_measurement}}\pysiglinewithargsret{\sphinxbfcode{get\_trajectory\_for\_measurement}}{}{}
Returns trajectory that is performed to execute the measurement corresponding to this viewpoint.
This measurement-trajectory is a straight line in cartesian space.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
Trajectory describing how to move the robot for this views measurement

\item[{Return type}] \leavevmode
moveit\_msgs/RobotTrajectory

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_trajectory\_to\_view() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.get_trajectory_to_view}}\pysiglinewithargsret{\sphinxbfcode{get\_trajectory\_to\_view}}{}{}
Returns the stored trajectory from a former state (might be robot’s current\_state or the end point of a previously executed trajectory) to
the start state of this views’s measurement trajectory. This is useful to connect multiple views into an execution plan.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
Trajectory from certain start state to this views’s measurement trajectory

\item[{Return type}] \leavevmode
moveit\_msgs/RobotTrajectory

\end{description}\end{quote}

\end{fulllineitems}

\index{reverse\_trajectory\_for\_measurement() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.reverse_trajectory_for_measurement}}\pysiglinewithargsret{\sphinxbfcode{reverse\_trajectory\_for\_measurement}}{}{}
Flips the measurement-trajectory of this viewpoint. The start-pose becomes the end-pose and vice versa. The execution time stays the same.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
None

\item[{Return type}] \leavevmode
NoneType

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_measurable\_surface\_point\_indices\_and\_uncertainties() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.set_measurable_surface_point_indices_and_uncertainties}}\pysiglinewithargsret{\sphinxbfcode{set\_measurable\_surface\_point\_indices\_and\_uncertainties}}{\emph{measurable\_point\_indices}, \emph{uncertainties}}{}
Sets the indices of surface points measurable by this view’s measurement-trajectory as well as their model-predicted uncertainties. 
The indices are abstract and only meaningful when connected to a concrete surface-point-list which is maintained externally of the View-scope.
Both lists must have the same length.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{measurable\_point\_indices} (\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{int}\sphinxstyleliteralemphasis{{]}}) \textendash{} List of the indices of points in an external surface\_point-list that can be measured by this view

\item {} 
\sphinxstyleliteralstrong{uncertainties} (\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{float}\sphinxstyleliteralemphasis{{]}}) \textendash{} List of uncertainty values for the measured surface\_point masked through the index at the same position

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_trajectory\_for\_measurement() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.set_trajectory_for_measurement}}\pysiglinewithargsret{\sphinxbfcode{set\_trajectory\_for\_measurement}}{\emph{trajectory\_for\_measurement}}{}
Trajectory that is performed to execute the measurement corresponding to this viewpoint.
This measurement-trajectory is a straight line in cartesian space.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{trajectory\_for\_measurement} (\sphinxstyleliteralemphasis{moveit\_msgs/RobotTrajectory}) \textendash{} Trajectory describing how to move the robot for this views measurement

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_trajectory\_to\_view() (agiprobot\_measurement.viewpoint.ViewPoint method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{module_view:agiprobot_measurement.viewpoint.ViewPoint.set_trajectory_to_view}}\pysiglinewithargsret{\sphinxbfcode{set\_trajectory\_to\_view}}{\emph{trajectory\_to\_view}}{}
Sets a trajectory that moves the robot to the start of the view’s measurement trajectory.
The trajectory can be arbitrary but must end at this start point. This is useful to connect multiple views into an execution plan.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{trajectory\_to\_view} (\sphinxstyleliteralemphasis{moveit\_msgs/RobotTrajectory}) \textendash{} Trajectory from certain start state to this views’s measurement trajectory

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{a}
\item {\sphinxstyleindexentry{agiprobot\_measurement.sensor\_model}}\sphinxstyleindexpageref{module_sensor_model:\detokenize{module-agiprobot_measurement.sensor_model}}
\item {\sphinxstyleindexentry{agiprobot\_measurement.trajectory\_manager}}\sphinxstyleindexpageref{module_trajectory_manager:\detokenize{module-agiprobot_measurement.trajectory_manager}}
\item {\sphinxstyleindexentry{agiprobot\_measurement.viewpoint}}\sphinxstyleindexpageref{module_view:\detokenize{module-agiprobot_measurement.viewpoint}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}